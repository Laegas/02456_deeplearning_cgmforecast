{
  "activation": "ReLU",
  "batch_size": 128,
  "dilations": [
    1,
    1,
    2,
    2,
    4
  ],
  "h1": 32,
  "h2": 32,
  "lr": 0.0026945649283714635,
  "wd": 0.03857382341282059
}